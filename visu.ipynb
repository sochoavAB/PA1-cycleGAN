{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        # Cargar solo las capas de características que necesitamos (hasta relu4_4)\n",
    "        vgg = torchvision.models.vgg19(pretrained=True).features[:26]\n",
    "        vgg.to(device)\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.vgg = vgg\n",
    "        self.criterion = nn.L1Loss()\n",
    "        \n",
    "        # Parámetros de normalización VGG\n",
    "        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
    "        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Asegurarnos de que los valores están en [0,1]\n",
    "        x = (x + 1) * 0.5  # de [-1,1] a [0,1]\n",
    "        y = (y + 1) * 0.5  # de [-1,1] a [0,1]\n",
    "        \n",
    "        # Normalizar con mean y std de VGG\n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        \n",
    "        # Obtener características y calcular pérdida\n",
    "        x_vgg = self.vgg(x.clamp(0, 1))\n",
    "        y_vgg = self.vgg(y.clamp(0, 1))\n",
    "        \n",
    "        return self.criterion(x_vgg, y_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)]\n",
      "PyTorch version: 2.2.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Define the generator\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n",
    "            nn.InstanceNorm2d(ngf),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [\n",
    "                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(ngf * mult * 2),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        # Resnet blocks\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResnetBlock(ngf * mult)]\n",
    "\n",
    "        # Upsampling\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(int(ngf * mult / 2)),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the dataset\n",
    "class CycleGANDataset(Dataset):\n",
    "    def __init__(self, npz_file, transform=None, fraction=0.1):\n",
    "        data = np.load(npz_file)\n",
    "        total_samples = len(data['arr_0'])\n",
    "        num_samples = int(total_samples * fraction)\n",
    "        \n",
    "        self.A = data['arr_0'][:num_samples]\n",
    "        self.B = data['arr_1'][:num_samples]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.A)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        A = self.A[idx].astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        B = self.B[idx].astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        A = torch.from_numpy(A).permute(2, 0, 1)  # Change from (H, W, C) to (C, H, W)\n",
    "        B = torch.from_numpy(B).permute(2, 0, 1)  # Change from (H, W, C) to (C, H, W)\n",
    "        \n",
    "        if self.transform:\n",
    "            A = self.transform(A)\n",
    "            B = self.transform(B)\n",
    "        \n",
    "        return A, B\n",
    "\n",
    "# Define the loss functions\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        if target_is_real:\n",
    "            target_tensor = self.real_label\n",
    "        else:\n",
    "            target_tensor = self.fake_label\n",
    "        return target_tensor.expand_as(input)\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)\n",
    "\n",
    "\n",
    "\n",
    "# Modificamos la función de entrenamiento para incluir VGG loss\n",
    "def train(netG_A2B, netG_B2A, netD_A, netD_B, train_loader, num_epochs, device):\n",
    "    criterionGAN = GANLoss().to(device)\n",
    "    criterionCycle = nn.L1Loss()\n",
    "    criterionIdt = nn.L1Loss()\n",
    "    criterionVGG = VGGLoss(device)  # Agregamos VGG loss\n",
    "\n",
    "    # Lambda para VGG loss\n",
    "    lambda_vgg = 10.0  # Puedes ajustar este valor\n",
    "\n",
    "    optimizer_G = optim.Adam(list(netG_A2B.parameters()) + list(netG_B2A.parameters()), \n",
    "                           lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D_A = optim.Adam(netD_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_D_B = optim.Adam(netD_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.1)\n",
    "    scheduler_D_A = optim.lr_scheduler.StepLR(optimizer_D_A, step_size=30, gamma=0.1)\n",
    "    scheduler_D_B = optim.lr_scheduler.StepLR(optimizer_D_B, step_size=30, gamma=0.1)\n",
    "\n",
    "    losses = {'G': [], 'D_A': [], 'D_B': [], 'VGG': []}  # Agregamos tracking de VGG loss\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = {'G': [], 'D_A': [], 'D_B': [], 'VGG': []}\n",
    "        \n",
    "        for i, (real_A, real_B) in enumerate(train_loader):\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "\n",
    "            # Train Generators\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            fake_B = netG_A2B(real_A)\n",
    "            fake_A = netG_B2A(real_B)\n",
    "\n",
    "            # Identity loss\n",
    "            loss_idt_A = criterionIdt(netG_A2B(real_B), real_B) * 5.0\n",
    "            loss_idt_B = criterionIdt(netG_B2A(real_A), real_A) * 5.0\n",
    "\n",
    "            # GAN loss\n",
    "            loss_GAN_A2B = criterionGAN(netD_B(fake_B), True)\n",
    "            loss_GAN_B2A = criterionGAN(netD_A(fake_A), True)\n",
    "\n",
    "            # Cycle loss\n",
    "            recovered_A = netG_B2A(fake_B)\n",
    "            recovered_B = netG_A2B(fake_A)\n",
    "            loss_cycle_ABA = criterionCycle(recovered_A, real_A) * 10.0\n",
    "            loss_cycle_BAB = criterionCycle(recovered_B, real_B) * 10.0\n",
    "\n",
    "            # VGG loss\n",
    "            loss_vgg_A = criterionVGG(fake_A, real_A) * lambda_vgg\n",
    "            loss_vgg_B = criterionVGG(fake_B, real_B) * lambda_vgg\n",
    "            loss_vgg = loss_vgg_A + loss_vgg_B\n",
    "\n",
    "            # Total generator loss\n",
    "            loss_G = (loss_GAN_A2B + loss_GAN_B2A + \n",
    "                     loss_cycle_ABA + loss_cycle_BAB + \n",
    "                     loss_idt_A + loss_idt_B + \n",
    "                     loss_vgg)\n",
    "            \n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # Train Discriminator A\n",
    "            optimizer_D_A.zero_grad()\n",
    "            loss_D_A = criterionGAN(netD_A(real_A), True) + criterionGAN(netD_A(fake_A.detach()), False)\n",
    "            loss_D_A.backward()\n",
    "            optimizer_D_A.step()\n",
    "\n",
    "            # Train Discriminator B\n",
    "            optimizer_D_B.zero_grad()\n",
    "            loss_D_B = criterionGAN(netD_B(real_B), True) + criterionGAN(netD_B(fake_B.detach()), False)\n",
    "            loss_D_B.backward()\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "            # Guardar losses\n",
    "            epoch_losses['G'].append(loss_G.item())\n",
    "            epoch_losses['D_A'].append(loss_D_A.item())\n",
    "            epoch_losses['D_B'].append(loss_D_B.item())\n",
    "            epoch_losses['VGG'].append(loss_vgg.item())\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "                      f'D_A_loss: {loss_D_A.item():.4f}, D_B_loss: {loss_D_B.item():.4f}, '\n",
    "                      f'G_loss: {loss_G.item():.4f}, VGG_loss: {loss_vgg.item():.4f}')\n",
    "\n",
    "        # Step the schedulers\n",
    "        scheduler_G.step()\n",
    "        scheduler_D_A.step()\n",
    "        scheduler_D_B.step()\n",
    "\n",
    "        # Calculate average losses for the epoch\n",
    "        for key in losses.keys():\n",
    "            losses[key].append(np.mean(epoch_losses[key]))\n",
    "\n",
    "        # Save models every epoch\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            torch.save(netG_A2B.state_dict(), f'netG_A2B_epoch_{epoch+1}.pth')\n",
    "            torch.save(netG_B2A.state_dict(), f'netG_B2A_epoch_{epoch+1}.pth')\n",
    "\n",
    "    return losses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(losses, save_path='training_losses.png'):\n",
    "    \"\"\"\n",
    "    Grafica las funciones de pérdida del entrenamiento\n",
    "    \n",
    "    Args:\n",
    "        losses (dict): Diccionario con las pérdidas {'G': [], 'D_A': [], 'D_B': [], 'VGG': []}\n",
    "        save_path (str): Ruta donde guardar la gráfica\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Crear el eje x (épocas)\n",
    "    epochs = range(1, len(losses['G']) + 1)\n",
    "    \n",
    "    # Graficar cada pérdida\n",
    "    plt.plot(epochs, losses['G'], 'b-', label='Generator Loss', linewidth=2)\n",
    "    plt.plot(epochs, losses['D_A'], 'r-', label='Discriminator A Loss', linewidth=2)\n",
    "    plt.plot(epochs, losses['D_B'], 'g-', label='Discriminator B Loss', linewidth=2)\n",
    "    plt.plot(epochs, losses['VGG'], 'm-', label='VGG Loss', linewidth=2)\n",
    "    \n",
    "    plt.title('Training Losses Over Time', size=14)\n",
    "    plt.xlabel('Epoch', size=12)\n",
    "    plt.ylabel('Loss', size=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=10)\n",
    "    \n",
    "    # Guardar la figura\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Loss plot saved as {save_path}\")\n",
    "\n",
    "# Modificar el main para incluir el plotting\n",
    "if __name__ == '__main__':\n",
    "    import torchvision\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize models\n",
    "    netG_A2B = Generator(3, 3).to(device)\n",
    "    netG_B2A = Generator(3, 3).to(device)\n",
    "    netD_A = Discriminator(3).to(device)\n",
    "    netD_B = Discriminator(3).to(device)\n",
    "\n",
    "    # Load datasets\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = CycleGANDataset('./data/confocal_exper_altogether_trainR_256.npz', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # # Train the model\n",
    "    # num_epochs = 100\n",
    "    # losses = train(netG_A2B, netG_B2A, netD_A, netD_B, train_loader, num_epochs, device)\n",
    "    \n",
    "    # # Plot and save losses\n",
    "    # plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as 'cyclegan_results.png'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Importamos las clases necesarias del código anterior\n",
    "\n",
    "def denormalize_image(image):\n",
    "    \"\"\"Convierte las imágenes de [-1,1] a [0,1] para visualización\"\"\"\n",
    "    return (image + 1) / 2\n",
    "\n",
    "def visualize_results(model_path, data_path, num_images=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Visualiza los resultados del modelo CycleGAN\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Ruta al archivo .pth del modelo\n",
    "        data_path (str): Ruta al archivo .npz con los datos\n",
    "        num_images (int): Número de imágenes a visualizar\n",
    "        device (str): Dispositivo a usar ('cuda' o 'cpu')\n",
    "    \"\"\"\n",
    "    # Configurar el dispositivo\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Cargar el modelo\n",
    "    model = Generator(3, 3)  # 3 canales de entrada y salida\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Preparar el dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    dataset = CycleGANDataset(data_path, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Configurar la visualización\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(15, 5*num_images))\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (real_A, real_B) in enumerate(dataloader):\n",
    "            if i >= num_images:\n",
    "                break\n",
    "                \n",
    "            # Mover datos al dispositivo\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            \n",
    "            # Generar imagen falsa\n",
    "            fake_B = model(real_A)\n",
    "            \n",
    "            # Convertir a CPU y numpy para visualización\n",
    "            real_A_np = denormalize_image(real_A[0]).cpu().numpy().transpose(1, 2, 0)\n",
    "            real_B_np = denormalize_image(real_B[0]).cpu().numpy().transpose(1, 2, 0)\n",
    "            fake_B_np = denormalize_image(fake_B[0]).cpu().numpy().transpose(1, 2, 0)\n",
    "            \n",
    "            # Visualizar las imágenes\n",
    "            axes[i, 0].imshow(real_A_np)\n",
    "            axes[i, 0].set_title('Input')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(real_B_np)\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(fake_B_np)\n",
    "            axes[i, 2].set_title('Generated')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.savefig('cyclegan_results.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Results saved as 'cyclegan_results.png'\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'netG_A2B_epoch_75.pth'  # Ajusta esto a la ruta de tu modelo\n",
    "    data_path = './data/confocal_exper_paired_filt_validsetR_256.npz'  # Ajusta esto a la ruta de tus datos\n",
    "    \n",
    "    visualize_results(\n",
    "        model_path=model_path,\n",
    "        data_path=data_path,\n",
    "        num_images=5,\n",
    "        device='cuda'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
